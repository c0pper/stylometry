{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO61bDlSVZ2JoV5/wrAWV3N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c0pper/stylometry/blob/main/expertiment_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive2', force_remount=True)"
      ],
      "metadata": {
        "id": "hgKttOgbOzc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers neptune-client neptune-tensorflow-keras --quiet\n",
        "!cp /content/drive2/MyDrive/simo/tokens.py /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9b2u_METnk1",
        "outputId": "961ef8bc-9697-49f7-f59a-23e84fc09616"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.9 MB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 326 kB 72.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 53.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 57.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 55.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 9.2 MB 51.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 63.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 76.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 130 kB 75.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 955 kB/s \n",
            "\u001b[K     |████████████████████████████████| 82 kB 701 kB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 225 kB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 11.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 71 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.7 MB/s \n",
            "\u001b[?25h  Building wheel for neptune-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for neptune-tensorflow-keras (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for strict-rfc3339 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YPUa1BXLFiYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4623d7ad-e081-4b01-a60b-45754f201be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive2\n"
          ]
        }
      ],
      "source": [
        "from typing import Union\n",
        "import math \n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from transformers import TFBertModel, BertTokenizer\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from requests import get\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from tensorflow.keras.models import load_model\n",
        "import time\n",
        "import json\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import neptune\n",
        "from neptune.new.integrations.tensorflow_keras import NeptuneCallback\n",
        "\n",
        "from tokens import neptune_token\n",
        "\n",
        "MODEL_SAVEPATH = \"/content/drive/MyDrive/simo/\"\n",
        "TIMENOW = datetime.now().strftime('%d-%m-%y-%H-%M')\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/logs\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/logs/sklearn\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/logs/bert\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/logs/stylo\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/models\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/models/sklearn\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/models/bert\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/simo/models/stylo\", exist_ok=True)\n",
        "\n",
        "def merge_datasets(dataset_list: list, target_col: str):\n",
        "  round_threshold = 0.49\n",
        "  processed_datasets = []\n",
        "  list90 = []\n",
        "  list10 = []\n",
        "\n",
        "  for idx, d in enumerate(dataset_list):\n",
        "    print(f\"original dataset {idx} shape\", d.shape)\n",
        "    original_shape = d.shape[0]\n",
        "\n",
        "    d90 = pd.DataFrame()\n",
        "    d10 = pd.DataFrame()\n",
        "    values_form_target = pd.unique(d[target_col].squeeze())\n",
        "    values_shapes = []\n",
        "    for v in values_form_target:\n",
        "      d_label = d[(d[target_col] == v)]\n",
        "      # print(d_label[target_col])\n",
        "      value_shape = d_label.shape[0]\n",
        "      values_shapes.append(value_shape)\n",
        "\n",
        "      d_label90perc, d_label10perc = np.split(d_label, [int(.9*len(d_label))])\n",
        "      print(f\"shape 90% for {v}: {d_label90perc.shape[0]} == shape*0.9: {value_shape*0.9}\")\n",
        "      print(f\"shape 10% for {v}: {d_label10perc.shape[0]} == shape*0.1: {value_shape*0.1}\")\n",
        "\n",
        "      d90 = d90.append(d_label90perc, ignore_index=True) # unisco i 2 sottodataset contenenti solo label1 e label2\n",
        "      d10 = d10.append(d_label10perc, ignore_index=True) # unisco i 2 sottodataset contenenti solo label1 e label2\n",
        "    assert(sum(values_shapes) == original_shape)\n",
        "    \n",
        "    d90 = d90.sample(frac=1, random_state=42) # mischio le righe per evitare che ci siano prima tutti label1 e poi tutti label2\n",
        "    d10 = d10.sample(frac=1, random_state=42)\n",
        "    assert((d90.shape[0] + d10.shape[0]) == original_shape)\n",
        "\n",
        "    print(\"\\n90% of dataset\\n\", d90.groupby(target_col)[target_col].count())# stampo il conteggio delle classi presenti nella nuova coppia di dataset derivata dall'originale\n",
        "    print(\"\\n10% of dataset\\n\", d10.groupby(target_col)[target_col].count(), \"\\n\\n\\n\")\n",
        "    processed_datasets.append((d90, d10))\n",
        "\n",
        "  for tup in processed_datasets:\n",
        "    df90 = tup[0]\n",
        "    df10 = tup[1]\n",
        "    list90.append(df90)\n",
        "    list10.append(df10)\n",
        "  merged90 = pd.DataFrame()\n",
        "  merged10 = pd.DataFrame()\n",
        "  for df in list90:\n",
        "    merged90 = merged90.append(df)\n",
        "  for df in list10:\n",
        "    merged10 = merged10.append(df)\n",
        "\n",
        "  return(merged90, merged10)\n",
        "\n",
        "def preprocess(text,stem=False):\n",
        "    stop_words = stopwords.words('english')\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    \n",
        "    text = text.lower()  # lowercase\n",
        "\n",
        "    text = re.sub(r'[!]+', '!', text)\n",
        "    text = re.sub(r'[?]+', '?', text)\n",
        "    text = re.sub(r'[.]+', '.', text)\n",
        "    text = re.sub(r'â€™', \"'\", text)\n",
        "    text = re.sub(r'â€œ', \"'\", text)\n",
        "    text = re.sub(r'â€', \"'\", text)\n",
        "    text = re.sub(r'â€˜', \"'\", text)\n",
        "    text = re.sub(r'â‚¬', \"€\", text)\n",
        "    text = re.sub(r\"'\", \"\", text)\n",
        "    text = re.sub('\\s+', ' ', text).strip()  # Remove and double spaces\n",
        "    text = re.sub(r'&amp;?', r'and', text)  # replace & -> and\n",
        "    text = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", text)  # Remove URLs\n",
        "    # remove some puncts (except . ! # ?)\n",
        "    text = re.sub(r'[:\"$%&\\*+,-/:;<=>@\\\\^_`{|}~]+', '', text)\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    text = emoji_pattern.sub(r'EMOJI', text)\n",
        "    \n",
        "    tokens = []\n",
        "    for token in text.split():\n",
        "        if token not in stop_words:\n",
        "            tokens.append(lemmatizer.lemmatize(token))\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "\n",
        "def apply_preprocess(xtrain, xvalid):\n",
        "  print(\"\\nPreprocessing texts...\")\n",
        "  print(f\"\\nBefore: {(xtrain.iloc[0][:50] + '..') if len(xtrain.iloc[0]) > 50 else xtrain.iloc[0]}\")\n",
        "  xtrain = xtrain.progress_apply(lambda x: preprocess(x))\n",
        "  xvalid = xvalid.progress_apply(lambda x: preprocess(x))\n",
        "  print(f\"\\nAfter: {(xtrain.iloc[0][:50] + '..') if len(xtrain.iloc[0]) > 50 else xtrain.iloc[0]}\")\n",
        "\n",
        "  return xtrain, xvalid\n",
        "\n",
        "\n",
        "class Experiment:\n",
        "  scaler = StandardScaler()\n",
        "  lbl_enc = preprocessing.LabelEncoder()\n",
        "\n",
        "  def __init__(self, dataset_path: Union[str, pd.DataFrame], split_size: float, target_col: str, model_savepath=MODEL_SAVEPATH):\n",
        "    self.dataset_path = dataset_path\n",
        "    self.split_size = split_size\n",
        "    self.target_col = target_col\n",
        "    if isinstance(self.dataset_path, str):\n",
        "      self.dataset_name = dataset_path.split(\".\")[-2].split(\"/\")[-1]\n",
        "    elif isinstance(self.dataset_path, pd.DataFrame):\n",
        "      self.dataset_name = input(\"Dataset name not found. Please enter dataset name: \")\n",
        "    self.model_savepath = model_savepath\n",
        "    self.nb_name = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].split(\".\")[0]\n",
        "    self.nb_url = \"https://colab.research.google.com/drive/\" + get('http://172.28.0.2:9000/api/sessions').json()[0][\"path\"].split(\"=\")[-1]\n",
        "\n",
        "    self.run = neptune.new.init(project=\"c0pper/fake-news\", api_token=neptune_token)\n",
        "\n",
        "\n",
        "  def load_split_dataset(self, dataset_path, dropna=False, do_split=True, use_scaler=False):\n",
        "    if isinstance(dataset_path, str): \n",
        "      format = dataset_path.split(\".\")[-1]\n",
        "      valid = {\"csv\", \"xlsx\", \"xls\"}\n",
        "      if format not in valid:\n",
        "        raise ValueError(f\"results: status must be one of {valid}.\")\n",
        "      elif format == \"csv\":\n",
        "        dataset = pd.read_csv(dataset_path)\n",
        "      elif (format == \"xlsx\" or format == \"xls\"):\n",
        "        dataset = pd.read_excel(dataset_path)\n",
        "    else:\n",
        "      dataset = dataset_path\n",
        "\n",
        "    print(\"Dataset head\\n\") \n",
        "    print(dataset.head())\n",
        "\n",
        "    X = dataset.drop(self.target_col, axis=1)\n",
        "    y = self.lbl_enc.fit_transform(dataset[self.target_col].values)\n",
        "\n",
        "    #dropping nans\n",
        "    if dropna:\n",
        "      print(\"DROPPING NAN\")\n",
        "      dataset = dataset.dropna(axis=0, how='any')\n",
        "\n",
        "    if use_scaler:\n",
        "      X = self.scaler.fit_transform(X)\n",
        "\n",
        "    \n",
        "    listy = list(self.lbl_enc.inverse_transform(y))\n",
        "    print(\"Dataset class distribution:\")\n",
        "    for i in set(listy):\n",
        "      print(i, listy.count(i))\n",
        "\n",
        "    if do_split:\n",
        "      xtrain, xvalid, ytrain, yvalid = train_test_split(X, y, random_state=42, test_size=self.split_size, shuffle=True)\n",
        "      return xtrain, xvalid, ytrain, yvalid\n",
        "    else:\n",
        "      return X, y\n",
        "\n",
        "\n",
        "  def print_cm(self, yvalid, predicted, target_names=[]): \n",
        "    cm = metrics.confusion_matrix(yvalid, predicted)\n",
        "    disp = metrics.ConfusionMatrixDisplay(cm, display_labels=target_names)\n",
        "    disp.plot(xticks_rotation=\"vertical\")\n",
        "\n",
        "  def print_report(self, predicted, yvalid, target_names=None):\n",
        "    report_dict = metrics.classification_report(yvalid, predicted, target_names=[str(x) for x in target_names], output_dict=True)\n",
        "    report_text = metrics.classification_report(yvalid, predicted, target_names=[str(x) for x in target_names])\n",
        "    print(report_text)\n",
        "    self.print_cm(yvalid, predicted, target_names=target_names)\n",
        "    return report_dict\n",
        "\n",
        "  \n",
        "  def load_test_dataset(self, testdataset_path, dropna):\n",
        "    X, y = self.load_split_dataset(testdataset_path, dropna=dropna, do_split=False)\n",
        "    target_names = self.lbl_enc.inverse_transform(list(set(y)))\n",
        "    return X, y, target_names\n",
        "\n",
        "\n",
        "  def confirm_stop_traking(self):    \n",
        "    tracking_stop_confirmation = input(f\"Stop neptune traking? Continue if you want to do evaluation (y/n)\")\n",
        "    if tracking_stop_confirmation == \"y\":\n",
        "      self.run.stop()\n",
        "      print(f\"Traking stopped\")\n",
        "    else:\n",
        "      print(f\"Continuing neptune tracking\")\n",
        "\n",
        "  def track_eval_metrics_neptune(self, report_dict: dict, modelpath: str, testdataset_path: str, exp_type: str):\n",
        "    test_ds_name = testdataset_path.split(\"/\")[-1]\n",
        "\n",
        "    self.run[f\"eval_parameters/{test_ds_name}\"] = report_dict\n",
        "    self.run[f\"eval_parameters/{test_ds_name}/model_path\"] = modelpath\n",
        "    self.run[\"sys/tags\"].add([\"eval\", exp_type])\n",
        "    self.run[f\"eval_parameters/{test_ds_name}/dataset_path\"] = testdataset_path\n",
        "    self.run[f\"eval_parameters/{test_ds_name}/dataset_name\"] = test_ds_name\n",
        "\n",
        "\n",
        "class PublicExpertiment(Experiment):\n",
        "  def __init__(self, dataset_path: Union[str, pd.DataFrame], split_size: float, target_col: str, text_col: str, model_savepath=MODEL_SAVEPATH, preprocess_dataset=True):\n",
        "    super().__init__(dataset_path, split_size, target_col, model_savepath)\n",
        "    self.text_col = text_col\n",
        "    self.preprocess_dataset = preprocess_dataset\n",
        "\n",
        "\n",
        "class ScikitExperiment(PublicExpertiment):\n",
        "  def __init__(self, dataset_path: Union[str, pd.DataFrame], split_size: float, target_col: str, text_col: str, algo, model_savepath=MODEL_SAVEPATH, preprocess_dataset=True):\n",
        "    super().__init__(dataset_path=dataset_path, \n",
        "                     split_size=split_size, \n",
        "                     target_col=target_col, \n",
        "                     text_col=text_col, \n",
        "                     model_savepath=model_savepath, \n",
        "                     preprocess_dataset=preprocess_dataset\n",
        "                     )\n",
        "    self.algo = algo\n",
        "\n",
        "\n",
        "  def train(self, dropna=False):\n",
        "    start = time.time()\n",
        "    xtrain, xvalid, ytrain, yvalid = super().load_split_dataset(self.dataset_path, dropna=dropna)\n",
        "    xtrain = xtrain[self.text_col]\n",
        "    xvalid = xvalid[self.text_col]\n",
        "\n",
        "    if self.preprocess_dataset:\n",
        "      xtrain, xvalid = apply_preprocess(xtrain, xvalid)\n",
        "      \n",
        "    clf_pipeline = Pipeline([\n",
        "     ('ctv', CountVectorizer()),\n",
        "     ('tfidf', TfidfTransformer()),\n",
        "     ('clf', self.algo),\n",
        "    ])\n",
        "    print(f\"Fitting pipeline: {clf_pipeline}\")\n",
        "    clf_pipeline.fit(xtrain, ytrain)\n",
        "    end = time.time()\n",
        "    elapsed = round(end - start, 2)\n",
        "    predicted = clf_pipeline.predict(xvalid)\n",
        "    report = super().print_report(predicted, yvalid, target_names=self.lbl_enc.inverse_transform(list(set(yvalid))))\n",
        "\n",
        "    self.save_model(clf_pipeline, self.lbl_enc)\n",
        "    print(\"Time elapsed in seconds: \", round(elapsed, 2))\n",
        "    \n",
        "    log_dict = self.log(self.model_savepath, self.dataset_name, len(xtrain)+len(xvalid), type(self.algo).__name__, elapsed, report)\n",
        "\n",
        "    self.confirm_stop_traking()\n",
        "\n",
        "    return log_dict\n",
        "\n",
        "  \n",
        "  def save_model(self, model, lbl_enc):\n",
        "    algo_name = type(self.algo).__name__\n",
        "    experiment_name = self.nb_name+\"__\"+self.dataset_name+\"__\"+algo_name\n",
        "    save_confirmation = input(f\"Save model {experiment_name}? (y/n)\")\n",
        "    if save_confirmation == \"y\":\n",
        "      filepath = f'{self.model_savepath}models/sklearn/{experiment_name}.pkl'\n",
        "      print(f\"Saving model to {filepath}\")\n",
        "      data = {\n",
        "          \"model\": model,\n",
        "          \"lbl_enc\": lbl_enc\n",
        "      }\n",
        "      joblib.dump(data, filepath)\n",
        "      self.run[\"model/model_was_saved\"] = True\n",
        "      self.run[\"model/model_location\"] = filepath\n",
        "    else:\n",
        "      print(\"Model wasn't saved\")\n",
        "      self.run[\"model/model_was_saved\"] = False\n",
        "\n",
        "\n",
        "  def load_model_and_predict(self, modelpath, X):\n",
        "    data = joblib.load(modelpath, mmap_mode=None)\n",
        "    model = data[\"model\"] #sklearn  \n",
        "    predicted = model.predict(X) \n",
        "    return predicted\n",
        "\n",
        "\n",
        "  def evaluate_on_other_dataset(self, testdataset_path: Union[str, pd.DataFrame], modelpath: str, dropna=False):\n",
        "    start = time.time()\n",
        "    if isinstance(testdataset_path, str):\n",
        "      format = testdataset_path.split(\".\")[-1]\n",
        "      valid = {\"csv\", \"xlsx\", \"xls\"}\n",
        "      if format not in valid:\n",
        "        raise ValueError(f\"results: status must be one of {valid}.\")\n",
        "      elif format == \"csv\":\n",
        "        dataset = pd.read_csv(testdataset_path)\n",
        "      elif (format == \"xlsx\" or format == \"xls\"):\n",
        "        dataset = pd.read_excel(testdataset_path)\n",
        "      X = dataset[self.text_col]\n",
        "      y = dataset[self.target_col]\n",
        "    elif isinstance(testdataset_path, pd.DataFrame):\n",
        "      X = testdataset_path[self.text_col]\n",
        "      y = testdataset_path[self.target_col]\n",
        "    print(X.shape)\n",
        "\n",
        "    if self.preprocess_dataset:\n",
        "      print(\"Preprocessing text...\")\n",
        "      X = X.progress_apply(lambda x: preprocess(x))\n",
        "    target_names = list(set(y))\n",
        "    lbl_enc = joblib.load(modelpath, mmap_mode=None)[\"lbl_enc\"]\n",
        "\n",
        "    predicted = self.load_model_and_predict(modelpath, X)\n",
        "    report_dict = super().print_report(predicted, lbl_enc.transform(y), target_names)\n",
        "    end = time.time()\n",
        "    elapsed = round(end - start, 2)\n",
        "    print(\"Time elapsed in seconds: \", round(elapsed, 2))\n",
        "    self.track_eval_metrics_neptune(report_dict, modelpath, testdataset_path, \"sklearn\")\n",
        "    self.confirm_stop_traking()\n",
        "\n",
        "\n",
        "  def log(self, savepath, datasetname, dataset_len, algo, elapsed, report):\n",
        "    log_dict = {\n",
        "        \"library_used\": type(self).__name__,\n",
        "        \"dataset_name\": datasetname,\n",
        "        \"dataset_lenght\": dataset_len,\n",
        "        \"notebook_url\": self.nb_url,\n",
        "        \"algo\": algo,\n",
        "        \"elapsed\": elapsed,\n",
        "        \"metrics_report\": report\n",
        "    }\n",
        "    algo_name = type(self.algo).__name__\n",
        "    experiment_name = self.nb_name+\"__\"+self.dataset_name+\"__\"+algo_name\n",
        "    filepath = f'{savepath}logs/sklearn/{experiment_name}_log.json'\n",
        "    with open(filepath, 'w') as fp:\n",
        "      json.dump(log_dict, fp)\n",
        "      print(\"Log saved to \", filepath)\n",
        "\n",
        "    self.run[\"parameters\"] = log_dict\n",
        "    self.run[\"sys/tags\"].add([\"sklearn\",\"training\"])\n",
        "\n",
        "    return log_dict\n",
        "\n",
        "\n",
        "class TFExperiment(PublicExpertiment):\n",
        "  def __init__(self, dataset_path: Union[str, pd.DataFrame], split_size: float, text_col, target_col: str, preprocess_dataset=True, model_savepath=MODEL_SAVEPATH, bert_pretrained_model='bert-large-uncased', bert_encode_maxlen=60):\n",
        "    super().__init__(dataset_path=dataset_path, \n",
        "                     split_size=split_size, \n",
        "                     text_col=text_col, \n",
        "                     target_col=target_col, \n",
        "                     preprocess_dataset=preprocess_dataset, \n",
        "                     model_savepath=model_savepath)\n",
        "    self.bert_pretrained_model = bert_pretrained_model\n",
        "    self.bert_encode_maxlen = bert_encode_maxlen\n",
        "  \n",
        "\n",
        "  def bert_encode(self, data, max_len) :\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\")\n",
        "    input_ids = [] \n",
        "    attention_masks = []\n",
        "    \n",
        "    for i in tqdm(range(len(data))):\n",
        "        encoded = bert_tokenizer.encode_plus(data.iloc[i],\n",
        "                                        add_special_tokens=True,\n",
        "                                        max_length=max_len,\n",
        "                                        pad_to_max_length=True,\n",
        "                                        return_attention_mask=True)\n",
        "        \n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "        \n",
        "    return np.array(input_ids),np.array(attention_masks)\n",
        "\n",
        "\n",
        "  def create_model(self, bert_encode_maxlen, bert_pretrained_model, optimizer, loss, metrics):\n",
        "    bert_layers = TFBertModel.from_pretrained(bert_pretrained_model)\n",
        "\n",
        "    input_ids = keras.Input(shape=(bert_encode_maxlen,),dtype='int32',name='input_ids')\n",
        "    attention_masks = keras.Input(shape=(bert_encode_maxlen,),dtype='int32',name='attention_masks')\n",
        "\n",
        "    output = bert_layers([input_ids,attention_masks])\n",
        "    output = output[1]\n",
        "    net = keras.layers.Dense(32,activation='relu')(output)\n",
        "    net = keras.layers.Dropout(0.2)(net)\n",
        "    net = keras.layers.Dense(1,activation='sigmoid')(net)\n",
        "    outputs = net\n",
        "    model = keras.models.Model(inputs = [input_ids,attention_masks],outputs = outputs)\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss,\n",
        "                  metrics=[metrics])\n",
        "    \n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "  def train(self, bert_encode_maxlen=None, bert_pretrained_model=None, dropna=False, epochs=10, optimizer=keras.optimizers.Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics='accuracy', callbacks=[]):\n",
        "    start = time.time()\n",
        "    if bert_encode_maxlen is None:\n",
        "      bert_encode_maxlen = self.bert_encode_maxlen\n",
        "    if bert_pretrained_model is None:\n",
        "      bert_pretrained_model = self.bert_pretrained_model\n",
        "\n",
        "    xtrain, xvalid, ytrain, yvalid = super().load_split_dataset(self.dataset_path, dropna=dropna)\n",
        "    xtrain = xtrain[self.text_col]\n",
        "    xvalid = xvalid[self.text_col]\n",
        "\n",
        "    if self.preprocess_dataset:\n",
        "      xtrain, xvalid = apply_preprocess(xtrain, xvalid)\n",
        "\n",
        "    train_input_ids, train_attention_masks = self.bert_encode(xtrain, bert_encode_maxlen)\n",
        "    val_input_ids, val_attention_masks = self.bert_encode(xvalid, bert_encode_maxlen)\n",
        "\n",
        "    model = self.create_model(bert_encode_maxlen, bert_pretrained_model, optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    neptune_cbk = NeptuneCallback(run=self.run, base_namespace='metrics')\n",
        "\n",
        "    history = model.fit(\n",
        "    [train_input_ids, train_attention_masks],\n",
        "    ytrain,\n",
        "    epochs=epochs,\n",
        "    # validation_data=([val_input_ids, val_attention_masks], y_val),\n",
        "    batch_size=32,\n",
        "    callbacks=[neptune_cbk]\n",
        "    )\n",
        "    end = time.time()\n",
        "    elapsed = round(end - start, 2)\n",
        "\n",
        "    predicted = model.predict([val_input_ids, val_attention_masks])\n",
        "    predicted = np.array(list(round(i[0]) for i in predicted))\n",
        "    report = super().print_report(predicted, yvalid, target_names=self.lbl_enc.inverse_transform(list(set(yvalid))))\n",
        "\n",
        "    self.save_model(model, self.lbl_enc)\n",
        "    print(\"Time elapsed in seconds: \", round(elapsed, 2))\n",
        "    \n",
        "    log_dict = self.log(self.model_savepath, self.dataset_name, model, len(xtrain)+len(xvalid), elapsed, bert_encode_maxlen, epochs, bert_pretrained_model, optimizer, report)\n",
        "    self.confirm_stop_traking()\n",
        "  \n",
        "  def save_model(self, model, lbl_enc):\n",
        "    algo_name = type(model).__name__\n",
        "    experiment_name = self.nb_name+\"__\"+self.dataset_name+\"__\"+algo_name\n",
        "    save_confirmation = input(f\"Save model {experiment_name}? (y/n)\")\n",
        "    if save_confirmation == \"y\":\n",
        "      filepath = f'{self.model_savepath}models/bert/{experiment_name}.h5'\n",
        "      lbl_enc_path = f'{self.model_savepath}models/bert/{experiment_name}__lbl_enc.pkl'\n",
        "      data = {\n",
        "          \"model\": model,\n",
        "          \"lbl_enc\": lbl_enc\n",
        "      }\n",
        "      print(f\"Saving model to {filepath}\")\n",
        "      # joblib.dump(data, filepath)\n",
        "      joblib.dump(lbl_enc, lbl_enc_path)\n",
        "      model.save(f'{self.model_savepath}models/bert/{experiment_name}.h5')\n",
        "      self.run[\"model/model_was_saved\"] = True\n",
        "      self.run[\"model/model_location\"] = filepath\n",
        "    else:\n",
        "      print(\"Model wasn't saved\")\n",
        "      self.run[\"model/model_was_saved\"] = False\n",
        "\n",
        "\n",
        "  def load_model_and_predict(self, modelpath, X):\n",
        "    # data = joblib.load(modelpath, mmap_mode=None)\n",
        "    # model = data[\"model\"]\n",
        "    model = load_model(modelpath, custom_objects={'TFBertModel':TFBertModel.from_pretrained(self.bert_pretrained_model)}) \n",
        "    predicted = model.predict(X) \n",
        "    predicted = np.array(list(round(i[0]) for i in predicted))\n",
        "    return predicted\n",
        "\n",
        "\n",
        "  def evaluate_on_other_dataset(self, testdataset_path, modelpath, text_col, fitted_lbl_enc, dropna=False):\n",
        "    start = time.time()\n",
        "    if isinstance(testdataset_path, str):\n",
        "      format = testdataset_path.split(\".\")[-1]\n",
        "      valid = {\"csv\", \"xlsx\", \"xls\"}\n",
        "      if format not in valid:\n",
        "        raise ValueError(f\"results: status must be one of {valid}.\")\n",
        "      elif format == \"csv\":\n",
        "        dataset = pd.read_csv(testdataset_path)\n",
        "      elif (format == \"xlsx\" or format == \"xls\"):\n",
        "        dataset = pd.read_excel(testdataset_path)\n",
        "      X = dataset[self.text_col]\n",
        "      y = dataset[self.target_col]\n",
        "    elif isinstance(testdataset_path, pd.DataFrame):\n",
        "      X = testdataset_path[self.text_col]\n",
        "      y = testdataset_path[self.target_col]\n",
        "      \n",
        "    target_names = list(set(y))\n",
        "    lbl_enc = joblib.load(modelpath, mmap_mode=None)[\"lbl_enc\"]\n",
        "\n",
        "    if self.preprocess_dataset:\n",
        "      print(\"Preprocessing text...\")\n",
        "      X = X.progress_apply(lambda x: preprocess(x))\n",
        "    input_ids, attention_masks = self.bert_encode(X, self.bert_encode_maxlen)\n",
        "\n",
        "    predicted = self.load_model_and_predict(modelpath, [input_ids, attention_masks])\n",
        "    report_dict = super().print_report(predicted, lbl_enc.transform(y), target_names)\n",
        "    end = time.time()\n",
        "    elapsed = round(end - start, 2)\n",
        "    print(\"Time elapsed in seconds: \", round(elapsed, 2))\n",
        "    self.track_eval_metrics_neptune(report_dict, modelpath, testdataset_path, \"bert\")\n",
        "    self.confirm_stop_traking()\n",
        "\n",
        "\n",
        "  def log(self, savepath, datasetname, model, dataset_len, elapsed, bert_encode_maxlen, epochs, bert_pretrained_model, optimizer, report):\n",
        "    log_dict = {\n",
        "        \"library_used\": type(self).__name__,\n",
        "        \"dataset_name\": datasetname,\n",
        "        \"dataset_lenght\": dataset_len,\n",
        "        \"notebook_url\": self.nb_url,\n",
        "        \"elapsed\": elapsed,\n",
        "        \"bert_encode_maxlen\": bert_encode_maxlen,\n",
        "        \"epochs\": epochs,\n",
        "        \"bert_pretrained_model\": bert_pretrained_model,\n",
        "        \"optimizer\": str(optimizer),\n",
        "        \"metrics_report\": report\n",
        "    }\n",
        "    algo_name = type(model).__name__\n",
        "    experiment_name = self.nb_name+\"__\"+self.dataset_name+\"__\"+algo_name\n",
        "    filepath = f'{savepath}logs/bert/{experiment_name}_log.json'\n",
        "    with open(filepath, 'w') as fp:\n",
        "      json.dump(log_dict, fp)\n",
        "      print(\"Log saved to \", filepath)\n",
        "\n",
        "    self.run[\"parameters\"] = log_dict\n",
        "    self.run[\"sys/tags\"].add([\"bert\",\"training\"])\n",
        "\n",
        "    return log_dict\n",
        "\n",
        "\n",
        "class StyloExperiment(Experiment):\n",
        "  def __init__(self, dataset_path: Union[str, pd.DataFrame], split_size: float, target_col: str, model_savepath=MODEL_SAVEPATH):\n",
        "    super().__init__(dataset_path=dataset_path, \n",
        "                     split_size=split_size, \n",
        "                     target_col=target_col, \n",
        "                     model_savepath=model_savepath)\n",
        "\n",
        "\n",
        "  def train(self, \n",
        "            epochs=10,\n",
        "            batch_size=512,\n",
        "            use_scaler=True, \n",
        "            n_layers=1, \n",
        "            n_units_input=51,\n",
        "            n_units_per_layer=None,\n",
        "            dropout_per_layer=None,\n",
        "            activation=\"relu\",\n",
        "            learning_rate=0.0014392587661767942,\n",
        "            optimizer=\"RMSprop\"\n",
        "            ):\n",
        "    start = time.time()\n",
        "    xtrain, xvalid, ytrain, yvalid = super().load_split_dataset(self.dataset_path, use_scaler=use_scaler)\n",
        "\n",
        "    if not n_units_per_layer:\n",
        "      n_units_per_layer = [80]\n",
        "    if not dropout_per_layer:\n",
        "      dropout_per_layer = [0.3203504513234906]\n",
        "\n",
        "    nn_parameters = {\n",
        "      \"n_layers\": n_layers,\n",
        "      \"n_units_input\": n_units_input,\n",
        "      \"activation\": activation,\n",
        "      \"n_units_per_layer\": n_units_per_layer,\n",
        "      \"dropout_per_layer\": dropout_per_layer,\n",
        "      \"learning_rate\": learning_rate,\n",
        "      \"optimizer\": optimizer\n",
        "    }\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(\n",
        "        Dense(\n",
        "            nn_parameters[\"n_units_input\"], \n",
        "            input_dim=xtrain.shape[1],\n",
        "            activation=nn_parameters[\"activation\"],\n",
        "          )\n",
        "    )\n",
        "    for i in range(nn_parameters[\"n_layers\"]):\n",
        "      model.add(\n",
        "          Dense(\n",
        "            nn_parameters[\"n_units_per_layer\"][i],\n",
        "            activation=nn_parameters[\"activation\"],\n",
        "          )\n",
        "      )\n",
        "      model.add(\n",
        "          Dropout(nn_parameters[\"dropout_per_layer\"][i])\n",
        "      )\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "    # We compile our model with a sampled learning rate.\n",
        "    learning_rate = nn_parameters[\"learning_rate\"]\n",
        "    optimizer_name = nn_parameters[\"optimizer\"]\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=getattr(keras.optimizers, optimizer_name)(learning_rate=learning_rate),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    neptune_cbk = NeptuneCallback(run=self.run, base_namespace='metrics')\n",
        "\n",
        "    history = model.fit(\n",
        "        xtrain,\n",
        "        ytrain,\n",
        "        batch_size=batch_size, \n",
        "        epochs=epochs,\n",
        "        validation_data=(xvalid, yvalid),\n",
        "        callbacks=[neptune_cbk]\n",
        "    )\n",
        "    end = time.time()\n",
        "    elapsed = round(end - start, 2)\n",
        "\n",
        "    predicted = model.predict(xvalid)\n",
        "    predicted = np.array(list(round(i[0]) for i in predicted))\n",
        "    report = super().print_report(predicted, yvalid, target_names=self.lbl_enc.inverse_transform(list(set(yvalid))))\n",
        "    self.save_model(model, self.scaler, self.lbl_enc)\n",
        "    print(\"Time elapsed in seconds: \", round(elapsed, 2))\n",
        "    \n",
        "    log_dict = self.log(self.model_savepath, self.dataset_name, model, len(xtrain)+len(xvalid), elapsed, epochs, nn_parameters, report)\n",
        "    self.confirm_stop_traking()\n",
        "\n",
        "  \n",
        "  def save_model(self, model, scaler, lbl_enc):\n",
        "    algo_name = type(model).__name__\n",
        "    experiment_name = self.nb_name+\"__\"+self.dataset_name+\"__\"+algo_name+\"_stilometria\"\n",
        "    save_confirmation = input(f\"Save model {experiment_name}? (y/n)\")\n",
        "    if save_confirmation == \"y\":\n",
        "      filepath = f'{self.model_savepath}models/stylo/{experiment_name}.pkl'\n",
        "      data = {\n",
        "          \"model\": model,\n",
        "          \"scaler\": scaler,\n",
        "          \"lbl_enc\": lbl_enc\n",
        "      }\n",
        "      print(f\"Saving model to {filepath}\")\n",
        "      joblib.dump(data, filepath)\n",
        "      # model.save(f'{self.model_savepath}{experiment_name}.h5')\n",
        "      self.run[\"model/model_was_saved\"] = True\n",
        "      self.run[\"model/model_location\"] = filepath\n",
        "    else:\n",
        "      print(\"Model wasn't saved\")\n",
        "      self.run[\"model/model_was_saved\"] = False\n",
        "\n",
        "  def load_model_and_predict(self, modelpath, X):\n",
        "    data = joblib.load(modelpath, mmap_mode=None)\n",
        "    model = data[\"model\"]\n",
        "    predicted = model.predict(X) \n",
        "    predicted = np.array(list(round(i[0]) for i in predicted))\n",
        "    return predicted\n",
        "\n",
        "\n",
        "  def evaluate_on_other_dataset(self, testdataset_path, modelpath, dropna=False, use_scaler=True):\n",
        "    start = time.time()\n",
        "    if isinstance(testdataset_path, str):\n",
        "      format = testdataset_path.split(\".\")[-1]\n",
        "      valid = {\"csv\", \"xlsx\", \"xls\"}\n",
        "      if format not in valid:\n",
        "        raise ValueError(f\"results: status must be one of {valid}.\")\n",
        "      elif format == \"csv\":\n",
        "        testdataset = pd.read_csv(testdataset_path)\n",
        "      elif (format == \"xlsx\" or format == \"xls\"):\n",
        "        testdataset = pd.read_excel(testdataset_path)\n",
        "      X = testdataset.drop(self.target_col, axis=1)\n",
        "      y = testdataset[self.target_col]\n",
        "    elif isinstance(testdataset_path, pd.DataFrame):\n",
        "      X = testdataset_path.drop(self.target_col, axis=1)\n",
        "      y = testdataset_path[self.target_col]\n",
        "\n",
        "    target_names = list(set(y))\n",
        "    lbl_enc = joblib.load(modelpath, mmap_mode=None)[\"lbl_enc\"]\n",
        "    scaler = joblib.load(modelpath, mmap_mode=None)[\"scaler\"]\n",
        "\n",
        "    if use_scaler:\n",
        "      X = scaler.transform(X)\n",
        "\n",
        "    predicted = self.load_model_and_predict(modelpath, X)\n",
        "    report_dict = super().print_report(predicted, lbl_enc.transform(y), target_names)\n",
        "    end = time.time()\n",
        "    elapsed = round(end - start, 2)\n",
        "    print(\"Time elapsed in seconds: \", round(elapsed, 2))\n",
        "    self.track_eval_metrics_neptune(report_dict, modelpath, testdataset_path, \"stylo\")\n",
        "    self.confirm_stop_traking()\n",
        "\n",
        "\n",
        "  def log(self, savepath, datasetname, model, dataset_len, elapsed, epochs, nn_parameters, report):\n",
        "    log_dict = {\n",
        "        \"library_used\": type(self).__name__,\n",
        "        \"dataset_name\": datasetname,\n",
        "        \"dataset_lenght\": dataset_len,\n",
        "        \"notebook_url\": self.nb_url,\n",
        "        \"elapsed\": elapsed,\n",
        "        \"epochs\": epochs,\n",
        "        \"nueral_net_parameters\": nn_parameters,\n",
        "        \"metrics_report\": report\n",
        "    }\n",
        "    algo_name = type(model).__name__\n",
        "    experiment_name = self.nb_name+\"__\"+self.dataset_name+\"__\"+algo_name+\"_stilometria\"\n",
        "    filepath = f'{savepath}logs/stylo/{experiment_name}_log.json'\n",
        "    with open(filepath, 'w') as fp:\n",
        "      json.dump(log_dict, fp)\n",
        "      print(\"Log saved to \", filepath)\n",
        "\n",
        "    self.run[\"parameters\"] = log_dict\n",
        "    self.run[\"sys/tags\"].add([\"stylo\",\"training\"])\n",
        "\n",
        "    return log_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/drive2/MyDrive/pan17-author-profiling-training-dataset-2017-03-10/en/df_pan2015gender.csv', usecols=[\"texts\", \"gender\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzJQZsOb2fnT",
        "outputId": "065c40bc-0084-416c-89c9-f1f2ef9acfe4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skl = ScikitExperiment(df,0.1,\"gender\",\"texts\",MultinomialNB())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o--Dwe4IzVNj",
        "outputId": "2e149b14-ca40-4c3a-9a7f-b4b14f1a0a21"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset name not found. Please enter dataset name: popo\n",
            "https://app.neptune.ai/c0pper/fake-news/e/FAK-15\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skl.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kgxPln5P1Okb",
        "outputId": "6224333a-7d2c-4418-e124-d48dc8fb59ce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset head\n",
            "\n",
            "                                               texts gender\n",
            "0  Things I want for my business cards but are to...   male\n",
            "1  \"painters produced their most highly valued wo...   male\n",
            "2  @username your new discussion layout is confus...   male\n",
            "3  I never really understood why game environment...   male\n",
            "4  @username 20k and 2048² on a gun, fine. But th...   male\n",
            "Dataset class distribution:\n",
            "male 6986\n",
            "female 7180\n",
            "\n",
            "Preprocessing texts...\n",
            "\n",
            "Before: RT @username: Computer Languages Character Distrib..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12749/12749 [00:02<00:00, 4882.10it/s]\n",
            "100%|██████████| 1417/1417 [00:00<00:00, 5055.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After: rt username computer language character distributi..\n",
            "Fitting pipeline: Pipeline(steps=[('ctv', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
            "                ('clf', MultinomialNB())])\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.67      0.78      0.72       735\n",
            "        male       0.71      0.59      0.65       682\n",
            "\n",
            "    accuracy                           0.69      1417\n",
            "   macro avg       0.69      0.69      0.68      1417\n",
            "weighted avg       0.69      0.69      0.69      1417\n",
            "\n",
            "Save model expertiment_classes__popo__MultinomialNB? (y/n)y\n",
            "Saving model to /content/drive/MyDrive/simo/models/sklearn/expertiment_classes__popo__MultinomialNB.pkl\n",
            "Time elapsed in seconds:  3.09\n",
            "Log saved to  /content/drive/MyDrive/simo/logs/sklearn/expertiment_classes__popo__MultinomialNB_log.json\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 37 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 37 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/c0pper/fake-news/e/FAK-15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'library_used': 'ScikitExperiment',\n",
              " 'dataset_name': 'popo',\n",
              " 'dataset_lenght': 14166,\n",
              " 'notebook_url': 'https://colab.research.google.com/drive/13pPw5eGVjETagjrCD3sVkS8OkPrkvMnm',\n",
              " 'algo': 'MultinomialNB',\n",
              " 'elapsed': 3.09,\n",
              " 'metrics_report': {'female': {'precision': 0.6729411764705883,\n",
              "   'recall': 0.7782312925170068,\n",
              "   'f1-score': 0.7217665615141957,\n",
              "   'support': 735},\n",
              "  'male': {'precision': 0.7125220458553791,\n",
              "   'recall': 0.592375366568915,\n",
              "   'f1-score': 0.6469175340272217,\n",
              "   'support': 682},\n",
              "  'accuracy': 0.6887791107974595,\n",
              "  'macro avg': {'precision': 0.6927316111629838,\n",
              "   'recall': 0.6853033295429609,\n",
              "   'f1-score': 0.6843420477707087,\n",
              "   'support': 1417},\n",
              "  'weighted avg': {'precision': 0.6919913902464722,\n",
              "   'recall': 0.6887791107974595,\n",
              "   'f1-score': 0.6857418355112908,\n",
              "   'support': 1417}}}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert = TFExperiment('/content/drive2/MyDrive/pan17-author-profiling-training-dataset-2017-03-10/en/df_gender1_2k.csv', 0.1, \"texts\", \"gender\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK1oe61CNOsA",
        "outputId": "390af4ae-2315-4ae4-9cbb-c144e2d4ad9f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://app.neptune.ai/c0pper/fake-news/e/FAK-14\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert.train(epochs=1,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V8rzc6gWbCY5",
        "outputId": "2ee38107-47f6-48af-a29b-beab8151e414"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset head\n",
            "\n",
            "   Unnamed: 0                                              texts  gender\n",
            "0           0  @TazzasaurusRex '05 Audi A4 Avant with only 60...  female\n",
            "1           1  @TazzasaurusRex nah it's not a write off, gett...  female\n",
            "2           2  @TazzasaurusRex ya both have been a long time ...  female\n",
            "3           3                               @TazzasaurusRex who?  female\n",
            "4           4  Probably my favourite post on reddit ever http...  female\n",
            "Dataset class distribution:\n",
            "male 600\n",
            "female 600\n",
            "\n",
            "Preprocessing texts...\n",
            "\n",
            "Before: Top Sensual Experience in Sydney: Lace | @scoopit ..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1080/1080 [00:00<00:00, 4630.28it/s]\n",
            "100%|██████████| 120/120 [00:00<00:00, 4529.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After: top sensual experience sydney lace scoopit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1080 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2308: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 1080/1080 [00:00<00:00, 2369.81it/s]\n",
            "  0%|          | 0/120 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "100%|██████████| 120/120 [00:00<00:00, 2094.42it/s]\n",
            "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 60)]         0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  335141888   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]']        \n",
            "                                tentions(last_hidde                                               \n",
            "                                n_state=(None, 60,                                                \n",
            "                                1024),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 1024),                                                         \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 32)           32800       ['tf_bert_model_1[0][1]']        \n",
            "                                                                                                  \n",
            " dropout_149 (Dropout)          (None, 32)           0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 1)            33          ['dropout_149[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 335,174,721\n",
            "Trainable params: 335,174,721\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "34/34 [==============================] - 71s 1s/step - loss: 0.6557 - accuracy: 0.6398\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      female       0.80      0.93      0.86        70\n",
            "        male       0.87      0.68      0.76        50\n",
            "\n",
            "    accuracy                           0.82       120\n",
            "   macro avg       0.84      0.80      0.81       120\n",
            "weighted avg       0.83      0.82      0.82       120\n",
            "\n",
            "Save model expertiment_classes__df_gender1_2k__Functional? (y/n)n\n",
            "Model wasn't saved\n",
            "Time elapsed in seconds:  78.98\n",
            "Log saved to  /content/drive/MyDrive/simo/logs/bert/expertiment_classes__df_gender1_2k__Functional_log.json\n",
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n",
            "Waiting for the remaining 38 operations to synchronize with Neptune. Do not kill this process.\n",
            "All 38 operations synced, thanks for waiting!\n",
            "Explore the metadata in the Neptune app:\n",
            "https://app.neptune.ai/c0pper/fake-news/e/FAK-14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_url = \"https://colab.research.google.com/drive/\" + get('http://172.28.0.2:9000/api/sessions').json()[0][\"path\"].split(\"=\")[-1]\n",
        "nb_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vTTuzd2BhwuC",
        "outputId": "cadbcbe8-b89e-460c-de83-ce7c1af7054b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://colab.research.google.com/drive/13pPw5eGVjETagjrCD3sVkS8OkPrkvMnm'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn20k = pd.read_csv(\"/content/drive2/MyDrive/simo/datasets/fake_news/fn20k_stil.csv\")\n"
      ],
      "metadata": {
        "id": "ylTocTJfjn1C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stylo = StyloExperiment(fn20k, split_size=0.1, target_col=\"Target\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNOEL1xWk7DK",
        "outputId": "d81bd8fe-7112-43b0-87b1-b76a19d218e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset name not found. Please enter dataset name: yyy\n",
            "https://app.neptune.ai/c0pper/fake-news/e/FAK-22\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stylo.train(epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "BG7YvrC3jxI6",
        "outputId": "08ea09c0-d87c-45fe-846b-381fdd7b2832"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-131cdda6c4f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstylo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stylo' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stylo.evaluate_on_other_dataset(\"/content/drive2/MyDrive/simo/datasets/fake_news/fn44k_stil.csv\", \n",
        "                                     '/content/drive2/MyDrive/simo/models/stylo/fake_news__merged[welfake,fn20k,fn44k]__Sequential_stilometria.pkl', \"Target\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "YaGw01Pjrcyr",
        "outputId": "2069732d-4e06-41df-92e3-ab930aa78f23"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        real       0.92      0.88      0.90     23343\n",
            "        fake       0.88      0.92      0.90     21417\n",
            "\n",
            "    accuracy                           0.90     44760\n",
            "   macro avg       0.90      0.90      0.90     44760\n",
            "weighted avg       0.90      0.90      0.90     44760\n",
            "\n",
            "Time elapsed in seconds:  5.46\n",
            "Stop neptune traking? Continue if you want to do evaluation (y/n)n\n",
            "Continuing neptune tracking\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}